{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\torch\\distributed\\_shard\\partial_tensor.py:40: UserWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  warnings.warn(DEPRECATE_MSG)\n",
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\torch\\distributed\\_shard\\replicated_tensor.py:20: UserWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  warnings.warn(DEPRECATE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "      def __init__(self, in_chanels=3, out_chanels=1):\n",
    "            super(CNNModel, self).__init__()\n",
    "            self.conv_layer1 = self._conv_layer_set(in_chanels, 16)\n",
    "            self.conv_layer2 = self._conv_layer_set(16, 32)\n",
    "            self.conv_layer3 = self._conv_layer_set(32, 64)\n",
    "            self.conv_layer4 = self._conv_layer_set(64, 128)\n",
    "            self.linear1 = self._dense_layer_set(128*8*8*8, 128)\n",
    "            self.linear2 = self._dense_layer_set(128, 64)\n",
    "            self.linear3 = self._dense_layer_set(64, out_chanels)\n",
    "            \n",
    "            \n",
    "      def _conv_layer_set(self, in_c, out_c):\n",
    "            conv_layer = nn.Sequential(\n",
    "            nn.Conv3d(in_c, out_c, kernel_size=3,padding=\"same\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            )\n",
    "            return conv_layer\n",
    "      def _dense_layer_set(self, in_c, out_c,drop= 0.2):\n",
    "            dense_layer = nn.Sequential(\n",
    "            nn.Linear(in_c, out_c),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(out_c),\n",
    "            nn.Dropout(p=drop)            \n",
    "            )\n",
    "            return dense_layer\n",
    "\n",
    "      def forward(self, x):\n",
    "            x = self.conv_layer1(x)\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.conv_layer3(x)\n",
    "            x = self.conv_layer4(x)\n",
    "            # print(x.shape)\n",
    "            x = x.view(x.size(0), -1)            \n",
    "            x = self.linear1(x)\n",
    "            x = self.linear2(x)\n",
    "            x = self.linear3(x)\n",
    "            return x\n",
    "            \n",
    "input_size = 128\n",
    "\n",
    "x = torch.randn(10, 3, input_size, input_size, input_size)\n",
    "\n",
    "model = CNNModel()\n",
    "y = model(x)\n",
    "y.shape\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LoadMolecules(Dataset):\n",
    "    def __init__(self, molecules_root, band_root, max_samples=100):\n",
    "        self.root = molecules_root\n",
    "        self.files = list(os.listdir(molecules_root))\n",
    "        if max_samples:\n",
    "            self.files = self.files[:min(max_samples, len(self.files))]\n",
    "        self.bandgap = np.loadtxt(\n",
    "            f'{band_root}/bandgaps.csv', dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(f'{self.root}/{self.files[idx]}').astype(np.float32)\n",
    "        data = np.transpose(data, (3, 0, 1, 2))\n",
    "\n",
    "        return data, self.bandgap[idx]\n",
    "\n",
    "\n",
    "class InMemoryDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data, batch_size):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size =int( len(data)*0.7)\n",
    "        self.val_size = int(len(data)*.2)\n",
    "        self.test_size = len(data) - self.train_size - self.val_size\n",
    "        self.train_data, self.val_data, self.test_data = None, None, None\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_data, self.val_data, self.test_data = torch.utils.data.random_split(\n",
    "            self.data, [self.train_size, self.val_size,   self.test_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandGap(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, save_every_n_epoch=10):\n",
    "        super(BandGap,self).__init__()\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters()\n",
    "        self.save_every_n_epoch = save_every_n_epoch\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.r2score = R2Score()\n",
    "        self.model = CNNModel().to(dev)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        r2 = self.r2score(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True)\n",
    "        self.log(\"train_r2\", r2, prog_bar=True, on_step=True)\n",
    "        return {\"loss\": loss, \"log\": {\"train_loss\": loss, \"train_r2\": r2}}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        r2 = self.r2score(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=True)\n",
    "        self.log(\"val_r2\", r2, prog_bar=True, on_step=True)\n",
    "        return {\"loss\": loss, \"log\": {\"val_loss\": loss, \"val_r2\": r2}}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        r2 = self.r2score(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=True)\n",
    "        self.log(\"test_r2\", r2, prog_bar=True, on_step=True)\n",
    "        return {\"loss\": loss, \"log\": {\"test_loss\": loss, \"test_r2\": r2}}\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "data  = LoadMolecules(molecules_root = r\"E:\\Datasets\\BandGap\\3d-boxels-molecule-for-bandgap-prediction\\Data\",band_root =r\"E:\\Datasets\\BandGap\\3d-boxels-molecule-for-bandgap-prediction\" , max_samples=12500)\n",
    "# data = [x for x in data]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='./checkpoints',\n",
    "    filename='{epoch}-{val_loss:.2f}-{val_r2:.2f}',\n",
    "    save_top_k=1,\n",
    "    monitor='val_loss',\n",
    "    every_n_epochs =1,\n",
    ")\n",
    "# EARLY STOPING callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.01,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "model = BandGap()\n",
    "# load checkpoint\n",
    "model = BandGap.load_from_checkpoint(checkpoint_path=r\"checkpoints\\1500 moleculas epoch=71-val_loss=0.92.ckpt\")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=100,log_every_n_steps=1,callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory E:\\Github\\band-gap\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type     | Params\n",
      "-------------------------------------\n",
      "0 | loss    | MSELoss  | 0     \n",
      "1 | r2score | R2Score  | 0     \n",
      "2 | model   | CNNModel | 8.7 M \n",
      "-------------------------------------\n",
      "8.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 M     Total params\n",
      "34.757    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022e4de66b6247ee9ecf7d29eb301e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93446a1fe8244ef8a03753602ee5c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "data_module = InMemoryDataModule(data,32)\n",
    "trainer.fit(model,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4944bdd1eb2e496984b725e44be78099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     val_loss_epoch         1.0289413928985596\n",
      "      val_r2_epoch          -0.1823505014181137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d7db39fe454d598fbd68e34c8e71f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch        1.0611859560012817\n",
      "      test_r2_epoch         -0.1461295485496521\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 1.0611859560012817, 'test_r2_epoch': -0.1461295485496521}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, data_module)\n",
    "trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.3103]], device='cuda:0', grad_fn=<NativeBatchNormBackward0>) 2.90567\n"
     ]
    }
   ],
   "source": [
    "x , y = data_module.test_data[742]\n",
    "# x to tensor\n",
    "x = torch.tensor(x).unsqueeze(0).to(dev)\n",
    "# model to eval\n",
    "model.eval()\n",
    "out = model(x)\n",
    "print(out, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "band-gap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
