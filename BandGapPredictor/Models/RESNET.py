import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math
from functools import partial
import torchvision
class Resnet(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(Resnet, self).__init__()
        
        self.resnet = torchvision.models.video.r3d_18(pretrained=True)
        self.linear1 = nn.Linear(400, 256)
        self.linear2 = nn.Linear(256, 256)
        self.linear3 = nn.Linear(256, 128)
        self.linear4 = nn.Linear(128,128)
        self.linear5 = nn.Linear(128,64)
        self.linear6 = nn.Linear(64,64)
        self.linear7 = nn.Linear(64,32)
        self.linear8 = nn.Linear(32,32)
        self.linear9 = nn.Linear(32,16)
        self.linear10 = nn.Linear(16,16)
        self.linear11= nn.Linear(16,8)
        self.linear12= nn.Linear(8,8)       
        self.linear12 = nn.Linear(8,1)
        self.batchnorm1 = nn.BatchNorm1d(256)
        self.batchnorm2 = nn.BatchNorm1d(256)
        self.batchnorm3 = nn.BatchNorm1d(128)
        self.batchnorm4 = nn.BatchNorm1d(128)
        self.batchnorm5 = nn.BatchNorm1d(64)
        self.batchnorm6 = nn.BatchNorm1d(64)
        self.batchnorm7 = nn.BatchNorm1d(32)
        self.batchnorm8 = nn.BatchNorm1d(32)
        self.batchnorm9 = nn.BatchNorm1d(16)
        self.batchnorm10 = nn.BatchNorm1d(16)
        self.batchnorm11 = nn.BatchNorm1d(8)
        self.batchnorm12 = nn.BatchNorm1d(8)        
        self.relu = nn.LeakyReLU()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        x = self.resnet(x)
        x = self.linear1(x)
        x = self.relu(x)
        x = self.batchnorm1(x)
        x = self.dropout(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.batchnorm2(x)
        x = self.dropout(x)
        x = self.linear3(x)
        x = self.relu(x)
        x = self.batchnorm3(x)
        x = self.dropout(x)
        x = self.linear4(x)
        x = self.relu(x)
        x = self.batchnorm4(x)
        x = self.dropout(x)
        x = self.linear5(x)
        x = self.relu(x)
        x = self.batchnorm5(x)
        x = self.dropout(x)
        x = self.linear6(x)
        x = self.relu(x)
        x = self.batchnorm6(x)
        x = self.dropout(x)
        x = self.linear7(x)
        x = self.relu(x)
        x = self.batchnorm7(x)
        x = self.dropout(x)
        x = self.linear8(x)
        x = self.relu(x)
        x = self.batchnorm8(x)
        x = self.dropout(x)
        x = self.linear9(x)
        x = self.relu(x)
        x = self.batchnorm9(x)
        x = self.dropout(x)
        x = self.linear10(x)
        x = self.relu(x)
        x = self.batchnorm10(x)
        x = self.dropout(x)
        x = self.linear11(x)
        x = self.relu(x)
        x = self.batchnorm11(x)
        x = self.dropout(x)
        x = self.linear12(x)
        x = self.relu(x)
        return x
